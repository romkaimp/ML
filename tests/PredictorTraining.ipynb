{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd58b09-422d-4e95-9a6a-efba9a0e2e09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pybit in /opt/conda/lib/python3.10/site-packages (5.8.0)\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from pybit) (3.21.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pybit) (2.32.3)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from pybit) (1.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pybit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pybit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pybit) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pybit) (2024.7.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.35.34)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.34 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.35.34)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.34->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.34->boto3) (2.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.34->boto3) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: EMD-signal in /opt/conda/lib/python3.10/site-packages (1.6.4)\n",
      "Requirement already satisfied: numpy>=1.12 in /opt/conda/lib/python3.10/site-packages (from EMD-signal) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.19 in /opt/conda/lib/python3.10/site-packages (from EMD-signal) (1.14.0)\n",
      "Requirement already satisfied: pathos>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from EMD-signal) (0.3.3)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from EMD-signal) (4.66.4)\n",
      "Requirement already satisfied: ppft>=1.7.6.9 in /opt/conda/lib/python3.10/site-packages (from pathos>=0.2.1->EMD-signal) (1.7.6.9)\n",
      "Requirement already satisfied: dill>=0.3.9 in /opt/conda/lib/python3.10/site-packages (from pathos>=0.2.1->EMD-signal) (0.3.9)\n",
      "Requirement already satisfied: pox>=0.3.5 in /opt/conda/lib/python3.10/site-packages (from pathos>=0.2.1->EMD-signal) (0.3.5)\n",
      "Requirement already satisfied: multiprocess>=0.70.17 in /opt/conda/lib/python3.10/site-packages (from pathos>=0.2.1->EMD-signal) (0.70.17)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pybit\n",
    "!{sys.executable} -m pip install boto3\n",
    "import subprocess\n",
    "from pybit.unified_trading import HTTP\n",
    "import boto3\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "!{sys.executable} -m pip install EMD-signal\n",
    "from PyEMD import CEEMDAN\n",
    "from builtins import RuntimeError\n",
    "\n",
    "from numpy import dtype\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class GRUNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_length, output_size=1, *, components=3, mean=0, scale=1):\n",
    "        super(GRUNetwork, self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.output_length = output_length\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.components = components\n",
    "\n",
    "        self.mean = mean\n",
    "        self.scale = scale\n",
    "        # x.shape = (b_size, input_size)\n",
    "        # Настройка GRU слоя\n",
    "        self.gru = nn.GRU(components + input_size, hidden_size, num_layers, batch_first=True, dropout=0.1)\n",
    "        self.decoder = nn.GRU(output_size, hidden_size, num_layers, batch_first=True, dropout=0.1)\n",
    "        # Полносвязный слой для превратить выходные данные GRU в требуемый формат\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, series_number, series_length = x.size()\n",
    "        # CEEMDAN decomposition\n",
    "        ceemdan = CEEMDAN(parallel=True)\n",
    "\n",
    "        # Для каждого временного ряда в батче проводим EMD и разбиваем его на три дополнительных временных ряда\n",
    "        decomposed_series = []\n",
    "        for i in range(batch_size):\n",
    "            k = (x[i].cpu().numpy().squeeze() - self.mean)/self.scale\n",
    "            imfs = ceemdan(k)  # проводим EMD на временном ряде\n",
    "            imfs = imfs[:self.components]  # берем только три первых IMFs\n",
    "            imfs = torch.cat((x[i].transpose(0, 1).cuda(), torch.tensor(imfs, dtype=torch.float32).cuda()), dim=0)\n",
    "            # Добавляем -1 размер для консистенции\n",
    "            decomposed_series.append(imfs.cuda())\n",
    "\n",
    "        x_decomposed = pad_sequence(decomposed_series, batch_first=True)\n",
    "        x_decomposed = x_decomposed.permute(0, 2, 1).reshape(x_decomposed.shape[0], -1, series_length+self.components).cuda()\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).cuda()\n",
    "        out, h_n = self.gru(x_decomposed, h0)\n",
    "        out_last = out[:, -1, :]\n",
    "\n",
    "        outputs = []\n",
    "        for _ in range(self.output_length):\n",
    "            output = self.fc(out_last)\n",
    "            outputs.append(output.unsqueeze(1))\n",
    "            out_last = self.decoder(output.unsqueeze(1), h_n)[0].squeeze(1)\n",
    "\n",
    "        return torch.cat(outputs, dim=1)*self.scale + self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f51aadfb-03b6-4cff-a5cb-e47fcb74de59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(SYMBOL):\n",
    "    session = boto3.session.Session()\n",
    "    s3 = session.client(\n",
    "        service_name='s3',\n",
    "        endpoint_url='https://storage.yandexcloud.net',\n",
    "        aws_access_key_id='YCAJEEvXFkR_Vlz_q0TNbK1f7',\n",
    "        aws_secret_access_key='YCPw07kPNEgOJVF0N93yReOErAl7RP0-5woP_Bgl',\n",
    "        region_name='ru-central1'\n",
    "    )\n",
    "    \n",
    "    bucket_name = 'test-actions'\n",
    "\n",
    "    x_train_file = f'train/trainX_{SYMBOL}.pt'\n",
    "    y_train_file = f'train/trainY_{SYMBOL}.pt'\n",
    "    x_test_file = f'test/testX_{SYMBOL}.pt'\n",
    "    y_test_file = f'test/testY_{SYMBOL}.pt'\n",
    "    s3.download_file(bucket_name, x_train_file, x_train_file[6:])\n",
    "    s3.download_file(bucket_name, y_train_file, y_train_file[6:])\n",
    "    s3.download_file(bucket_name, x_test_file, x_test_file[5:])\n",
    "    s3.download_file(bucket_name, y_test_file, y_test_file[5:])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(x_train_file[6:])\n",
    "    x_train, y_train = torch.load(f'trainX_{SYMBOL}.pt', weights_only=True).to(torch.float32).cuda(), torch.load(\n",
    "        f'trainY_{SYMBOL}.pt', weights_only=True).to(torch.float32).cuda()\n",
    "    x_test, y_test = torch.load(f'testX_{SYMBOL}.pt', weights_only=True).to(torch.float32).cuda(), torch.load(\n",
    "        f'testY_{SYMBOL}.pt', weights_only=True).to(torch.float32).cuda()\n",
    "\n",
    "    mean, std = x_train.squeeze().reshape(-1).detach().mean().item(), x_train.squeeze().reshape(\n",
    "        -1).detach().std().item()\n",
    "    dataset = TensorDataset(x_train, y_train)\n",
    "    validation = TensorDataset(x_test, y_test)\n",
    "\n",
    "    batch_size = 5\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(validation, batch_size=2, shuffle=True)\n",
    "\n",
    "    gru = GRUNetwork(1, 30, 2, 10, components=1, mean=mean, scale=std)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    gru.cuda()\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(gru.parameters(), lr=0.9)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "    # Обучение модели\n",
    "    num_epochs = 50\n",
    "    patience = 3\n",
    "    target_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (batch_x, batch_y) in enumerate(dataloader):\n",
    "            gru.train()\n",
    "            outputs = gru(batch_x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        gru.eval()  # Переключаем модель в режим оценки\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():  # Выключаем вычисление градиентов\n",
    "            for batch_x, batch_y in val_dataloader:\n",
    "                outputs = gru(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_dataloader)  # Средняя ошибка на валидации\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Реализация ранней остановки\n",
    "        if val_loss < target_loss:\n",
    "            target_loss = val_loss\n",
    "            patience_counter = 0  # Сбрасываем счетчик\n",
    "        else:\n",
    "            patience_counter += 1  # Увеличиваем счетчик\n",
    "\n",
    "        # Проверяем, если сохранять, если ошибка стабильна\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Ошибка валидации не уменьшается, остановка обучения.\")\n",
    "            break\n",
    "\n",
    "    model_file = f'gru_{SYMBOL}.onnx'\n",
    "    torch.onnx.export(gru, x_train, model_file, export_params=True)\n",
    "    s3.upload_file(f'gru_{SYMBOL}.onnx', bucket_name, 'model/'+model_file)\n",
    "\n",
    "    weights_file = f'weights_{SYMBOL}.pt'\n",
    "    torch.save(gru.state_dict(), weights_file)\n",
    "    s3.upload_file(weights_file, bucket_name, 'model/'+weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cf3cef-0738-44ca-bd68-fdadd05b19f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX_BTCUSDT.pt\n"
     ]
    }
   ],
   "source": [
    "# Создайте объект клиента API\n",
    "client = HTTP()\n",
    "\n",
    "# Получите информацию о рынке\n",
    "market_data = client.get_tickers(category='spot')\n",
    "\n",
    "# Отсортируйте токены по объему торгов, чтобы найти самые популярные\n",
    "sorted_tickers = sorted(filter(lambda x: x.get('symbol').endswith('USDT') and not x.get('symbol').startswith('USD'), market_data.get('result', {}).get('list', [])), key=lambda x: float(x['turnover24h']), reverse=True)\n",
    "\n",
    "# Выведите топ несколько популярных токенов\n",
    "top_tickers = sorted_tickers[:10]  # например, топ 5\n",
    "#for ticker in top_tickers:\n",
    "#    print(f\"Токен: {ticker['symbol']}, Объём за 24ч: {ticker['turnover24h']}\")\n",
    "\n",
    "symbols = [ticker['symbol'] for ticker in top_tickers]\n",
    "\n",
    "for symbol in symbols:\n",
    "    main(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8af61-e31a-4d21-8d47-fbfad7a191a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
