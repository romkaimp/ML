{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-06T15:43:52.557228Z",
     "start_time": "2024-10-06T15:43:42.471576Z"
    }
   },
   "source": [
    "import numpy\n",
    "from pybit.unified_trading import HTTP\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from models.TS.GRUPipeline import GRUNetwork\n",
    "import time\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T15:43:52.576595Z",
     "start_time": "2024-10-06T15:43:52.573210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SYMBOL = 'SOLUSDT'\n",
    "API_KEY = 'Z8QsHgyTpwinr9K2Ya'\n",
    "API_SECRET = '5QfjbglBfFK5A8RqGvcvdw8hCF4Yjv5sByOn' # март"
   ],
   "id": "da97c30e685f1164",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T15:43:52.783496Z",
     "start_time": "2024-10-06T15:43:52.780902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cl = HTTP(\n",
    "    \n",
    ")"
   ],
   "id": "8478453b67e903bd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T15:57:02.476182Z",
     "start_time": "2024-10-06T15:43:52.790563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#butch_size = 5\n",
    "START_TIMESTAMP = '1711929617184'\n",
    "time_series = 1000 #  количество изначальных временных рядов в разные промежутки времени, с количеством измерений t_s_l\n",
    "time_series_length = 10 #  количество сэмплов из ts, на которые мы делим временной ряд\n",
    "time_series_sample = 20 #  количество сделок в одном временном ряду\n",
    "\n",
    "time_series_real_l = time_series_length + time_series_sample - 1\n",
    "time_stamps = [START_TIMESTAMP]\n",
    "\n",
    "train_data = np.ndarray(shape=(time_series, time_series_length, time_series_sample))\n",
    "volumes = np.ndarray(shape=time_series_real_l*time_series)\n",
    "all_price = np.ndarray(shape=time_series_real_l*time_series)\n",
    "\n",
    "for i in range(time_series):\n",
    "    kline = cl.get_kline(\n",
    "        category=\"spot\",\n",
    "        symbol=SYMBOL,\n",
    "        start=time_stamps[-1],\n",
    "        interval=1,\n",
    "        limit = time_series_real_l\n",
    "    )\n",
    "    if kline.get('result', []).get('list', [])[-1][0] < time_stamps[-1]:\n",
    "        time_stamps[-1] = kline.get('result', []).get('list', [])[-2][0]\n",
    "        time.sleep(0.05)\n",
    "        kline = cl.get_kline(\n",
    "            category=\"spot\",\n",
    "            symbol=SYMBOL,\n",
    "            start=time_stamps[-1],\n",
    "            interval=1,\n",
    "            limit = time_series_real_l\n",
    "        )\n",
    "    if i % 120 == 0:\n",
    "        time.sleep(5)\n",
    "    time_stamps.append(str( int(kline.get('result', []).get('list', [])[0][0]) + 10000))\n",
    "    \n",
    "    volumes[i*time_series_real_l:(i+1)*time_series_real_l] = np.array([i[5] for i in kline.get('result', []).get('list', [])[::-1]], dtype=float)\n",
    "    all_price[i*time_series_real_l:(i+1)*time_series_real_l] = np.array([i[4] for i in kline.get('result', []).get('list', [])[::-1]], dtype=float)\n",
    "    \n",
    "    prices = np.array([i[4] for i in kline.get('result', []).get('list', [])[::-1]], dtype=float)         \n",
    "    train_data[i] = np.array(\n",
    "        [prices[i:time_series_sample+i] for i in range(time_series_real_l-time_series_sample+1)], dtype=float\n",
    "    ).reshape(time_series_real_l-time_series_sample+1, time_series_sample)     "
   ],
   "id": "95918b1267c53017",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T15:57:02.492626Z",
     "start_time": "2024-10-06T15:57:02.488548Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_data.shape)",
   "id": "c3b1106ba19feb74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10, 20)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T15:58:28.504134Z",
     "start_time": "2024-10-06T15:58:28.498594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_size = int(time_series * 0.8)\n",
    "prediction_length = 10\n",
    "idxs = np.random.choice((time_series-1), size=train_size)\n",
    "x_train, y_train, = torch.tensor(train_data[idxs]), torch.tensor(train_data[idxs+1][:, 0, :prediction_length])\n",
    "print(x_train.shape, y_train.shape)"
   ],
   "id": "22ff2481b6610c01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 10, 20]) torch.Size([800, 10])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T15:58:31.539160Z",
     "start_time": "2024-10-06T15:58:31.229294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "synthetic_data_size = 2000\n",
    "#synthetic_data_x = np.ndarray(shape=(synthetic_data_size, time_series_length, time_series_sample))\n",
    "#synthetic_data_y = np.ndarray(shape=(synthetic_data_size, prediction_length))\n",
    "synthetic_data_x = []\n",
    "synthetic_data_y = []\n",
    "for i in range(2000):\n",
    "    idx = int(np.random.rand()*(train_size-2)) #  можно взять предпоследний элемент, потому что по следующему эл-ту будет идти ошибка\n",
    "    size_s = min(time_series_length-1, max(2, int(np.random.normal(time_series_length/2, time_series_length/4))))\n",
    "    samples_idx = np.random.choice(time_series_length-1, size = size_s, replace=True)\n",
    "    samples_idx.sort()\n",
    "    samples_idx = np.append(samples_idx, time_series_length-1)\n",
    "    el_x = x_train[idx][samples_idx]\n",
    "    el_y = x_train[idx+1][0, :prediction_length]\n",
    "    synthetic_data_x.append(el_x.clone().detach().requires_grad_(True))\n",
    "    synthetic_data_y.append(el_y.clone().detach().requires_grad_(True))\n",
    "synthetic_data_x = pad_sequence(synthetic_data_x, batch_first=True)\n",
    "synthetic_data_y = torch.stack(synthetic_data_y)\n",
    "print(synthetic_data_x.shape, synthetic_data_y.shape)"
   ],
   "id": "8645e5276aaf42a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 10, 20]) torch.Size([2000, 10])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T16:15:52.174451Z",
     "start_time": "2024-10-06T16:15:52.072731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save(torch.concat((x_train, synthetic_data_x), dim=0), f'train_x_{SYMBOL}.pt')\n",
    "torch.save(torch.concat((y_train, synthetic_data_y), dim=0), f'train_y_{SYMBOL}.pt')\n",
    "dataset = TensorDataset(torch.concat((x_train, synthetic_data_x), dim=0), torch.concat((y_train, synthetic_data_y), dim=0))\n",
    "batch_size = 5\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "2cba69a9966fbf01",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T16:35:49.801416Z",
     "start_time": "2024-10-06T16:35:49.796278Z"
    }
   },
   "cell_type": "code",
   "source": "gru = GRUNetwork(time_series_sample, 50, 2, prediction_length, 1)",
   "id": "f0c810c71d6b74f8",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T15:57:04.985190Z",
     "start_time": "2024-10-06T15:57:03.031494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(gru.parameters(), lr=0.01)\n",
    "\n",
    "# Обучение модели\n",
    "num_epochs = 1000\n",
    "x_train = x_train.view(x_train.size(0), x_train.size(1), -1)  # Преобразование для приемлемого формата\n",
    "y_train = y_train.view(y_train.size(0), -1)  # Преобразование для целевых значений\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (batch_x, batch_y) in enumerate(dataloader):\n",
    "        gru.train()\n",
    "        outputs = gru(batch_x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ],
   "id": "b0fcfef8b6260655",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Неверная форма IMFs: torch.Size([20, 3])\nИзначальные данные - tensor([[135.6900, 135.8400, 135.6200, 135.5800, 135.6700, 136.1900, 136.6300,\n         136.3300, 136.3600, 136.3300, 136.6100, 136.6400, 136.1700, 136.3300,\n         136.5000, 136.4000, 136.3100, 136.2600, 135.9700, 135.9100],\n        [135.6700, 136.1900, 136.6300, 136.3300, 136.3600, 136.3300, 136.6100,\n         136.6400, 136.1700, 136.3300, 136.5000, 136.4000, 136.3100, 136.2600,\n         135.9700, 135.9100, 135.9500, 135.9600, 135.9600, 135.6100],\n        [136.1900, 136.6300, 136.3300, 136.3600, 136.3300, 136.6100, 136.6400,\n         136.1700, 136.3300, 136.5000, 136.4000, 136.3100, 136.2600, 135.9700,\n         135.9100, 135.9500, 135.9600, 135.9600, 135.6100, 135.3500],\n        [136.6300, 136.3300, 136.3600, 136.3300, 136.6100, 136.6400, 136.1700,\n         136.3300, 136.5000, 136.4000, 136.3100, 136.2600, 135.9700, 135.9100,\n         135.9500, 135.9600, 135.9600, 135.6100, 135.3500, 135.4900],\n        [136.3600, 136.3300, 136.6100, 136.6400, 136.1700, 136.3300, 136.5000,\n         136.4000, 136.3100, 136.2600, 135.9700, 135.9100, 135.9500, 135.9600,\n         135.9600, 135.6100, 135.3500, 135.4900, 135.1000, 135.0300],\n        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n       dtype=torch.float64)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (batch_x, batch_y) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader):\n\u001B[0;32m     11\u001B[0m     gru\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m---> 12\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mgru\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_x\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     14\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, batch_y)\n",
      "File \u001B[1;32mE:\\FASTAPI\\PEINO\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\FASTAPI\\PEINO\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mE:\\FASTAPI\\PEINO\\models\\TS\\GRUPipeline.py:33\u001B[0m, in \u001B[0;36mGRUNetwork.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     30\u001B[0m     imfs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(imfs)\u001B[38;5;241m.\u001B[39mto(x\u001B[38;5;241m.\u001B[39mdevice)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m0\u001B[39m,\n\u001B[0;32m     31\u001B[0m                                                      \u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# преобразуем обратно в тензор и делаем transpose\u001B[39;00m\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m imfs\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m imfs\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m!=\u001B[39m sample_length:\n\u001B[1;32m---> 33\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mНеверная форма IMFs: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimfs\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mИзначальные данные - \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx[i]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     34\u001B[0m     sample_decompositions\u001B[38;5;241m.\u001B[39mappend(imfs)\n\u001B[0;32m     36\u001B[0m decomposed_series\u001B[38;5;241m.\u001B[39mappend(torch\u001B[38;5;241m.\u001B[39mstack(sample_decompositions, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n",
      "\u001B[1;31mValueError\u001B[0m: Неверная форма IMFs: torch.Size([20, 3])\nИзначальные данные - tensor([[135.6900, 135.8400, 135.6200, 135.5800, 135.6700, 136.1900, 136.6300,\n         136.3300, 136.3600, 136.3300, 136.6100, 136.6400, 136.1700, 136.3300,\n         136.5000, 136.4000, 136.3100, 136.2600, 135.9700, 135.9100],\n        [135.6700, 136.1900, 136.6300, 136.3300, 136.3600, 136.3300, 136.6100,\n         136.6400, 136.1700, 136.3300, 136.5000, 136.4000, 136.3100, 136.2600,\n         135.9700, 135.9100, 135.9500, 135.9600, 135.9600, 135.6100],\n        [136.1900, 136.6300, 136.3300, 136.3600, 136.3300, 136.6100, 136.6400,\n         136.1700, 136.3300, 136.5000, 136.4000, 136.3100, 136.2600, 135.9700,\n         135.9100, 135.9500, 135.9600, 135.9600, 135.6100, 135.3500],\n        [136.6300, 136.3300, 136.3600, 136.3300, 136.6100, 136.6400, 136.1700,\n         136.3300, 136.5000, 136.4000, 136.3100, 136.2600, 135.9700, 135.9100,\n         135.9500, 135.9600, 135.9600, 135.6100, 135.3500, 135.4900],\n        [136.3600, 136.3300, 136.6100, 136.6400, 136.1700, 136.3300, 136.5000,\n         136.4000, 136.3100, 136.2600, 135.9700, 135.9100, 135.9500, 135.9600,\n         135.9600, 135.6100, 135.3500, 135.4900, 135.1000, 135.0300],\n        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n       dtype=torch.float64)"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
