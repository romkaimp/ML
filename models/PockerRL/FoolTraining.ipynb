{
 "cells": [
  {
   "cell_type": "code",
   "id": "7038ae9c77d438d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T20:59:56.553462Z",
     "start_time": "2025-07-21T20:59:55.964185Z"
    }
   },
   "source": [
    "from Environment import FoolGame, GameState, GameTreeNode\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-21T20:59:56.563716Z",
     "start_time": "2025-07-21T20:59:56.560461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "infoLogger = logging.getLogger(__name__)\n",
    "infoLogger.setLevel(logging.INFO)\n",
    "py_handler = logging.FileHandler(f\"{__name__}.log\", mode='w')\n",
    "py_formatter = logging.Formatter(\"%(name)s %(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "py_handler.setFormatter(py_formatter)\n",
    "infoLogger.addHandler(py_handler)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T20:59:56.682245Z",
     "start_time": "2025-07-21T20:59:56.679236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "names = {0: '6', 1: '7', 2: '8', 3: '9', 4: '10', 5: \"jack\", 6: \"queen\",\n",
    "             7: \"king\", 8: \"ace\"}\n",
    "game = FoolGame(36, 4, 6, 3, names=names)\n",
    "game.redo()"
   ],
   "id": "fe03e8ae60248acb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T20:59:56.689759Z",
     "start_time": "2025-07-21T20:59:56.686067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "game.step(24, save=True)\n",
    "print(game.state_history.restore(-1).get_state())\n"
   ],
   "id": "b730d22aa5fde69d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'players_banks': [[(26, {'power': 'ace', 'type': 2}, {'power': 8, 'type': 2}, array([1, 0, 1, 0, 0, 1])), (8, {'power': 'ace', 'type': 0}, {'power': 8, 'type': 0}, array([0, 0, 1, 0, 0, 1])), (6, {'power': 'queen', 'type': 0}, {'power': 6, 'type': 0}, array([0, 0, 0, 1, 1, 1])), (4, {'power': '10', 'type': 0}, {'power': 4, 'type': 0}, array([0, 0, 0, 1, 0, 1])), (32, {'power': 'jack', 'type': 3}, {'power': 5, 'type': 3}, array([1, 1, 0, 1, 1, 0])), (16, {'power': 'king', 'type': 1}, {'power': 7, 'type': 1}, array([0, 1, 1, 0, 0, 0]))], [(18, {'power': '6', 'type': 2}, {'power': 0, 'type': 2}, array([1, 0, 0, 0, 0, 1])), (3, {'power': '9', 'type': 0}, {'power': 3, 'type': 0}, array([0, 0, 0, 1, 0, 0])), (23, {'power': 'jack', 'type': 2}, {'power': 5, 'type': 2}, array([1, 0, 0, 1, 1, 0])), (7, {'power': 'king', 'type': 0}, {'power': 7, 'type': 0}, array([0, 0, 1, 0, 0, 0])), (25, {'power': 'king', 'type': 2}, {'power': 7, 'type': 2}, array([1, 0, 1, 0, 0, 0])), (19, {'power': '7', 'type': 2}, {'power': 1, 'type': 2}, array([1, 0, 0, 0, 1, 0]))], [(27, {'power': '6', 'type': 3}, {'power': 0, 'type': 3}, array([1, 1, 0, 0, 0, 1])), (2, {'power': '8', 'type': 0}, {'power': 2, 'type': 0}, array([0, 0, 0, 0, 1, 1])), (33, {'power': 'queen', 'type': 3}, {'power': 6, 'type': 3}, array([1, 1, 0, 1, 1, 1])), (10, {'power': '7', 'type': 1}, {'power': 1, 'type': 1}, array([0, 1, 0, 0, 1, 0])), (0, {'power': '6', 'type': 0}, {'power': 0, 'type': 0}, array([0, 0, 0, 0, 0, 1])), (5, {'power': 'jack', 'type': 0}, {'power': 5, 'type': 0}, array([0, 0, 0, 1, 1, 0]))]], 'players_info': [[], [], []], 'table': [], 'bita': [], 'target': [(24, {'power': 'queen', 'type': 2}, {'power': 6, 'type': 2}, array([1, 0, 0, 1, 1, 1]))], 'finished_players': [], 'busy_cards': [26, 18, 27, 8, 3, 2, 6, 23, 33, 4, 7, 10, 32, 25, 0, 16, 19, 5, 22], 'h': ['attacked'], 'role': 0, 'round': 0, 'cosir': (22, {'power': '10', 'type': 2}, {'power': 4, 'type': 2}, array([1, 0, 0, 1, 0, 1]))}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T20:59:56.705601Z",
     "start_time": "2025-07-21T20:59:56.697222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_observations(state: dict) -> tuple[np.ndarray, np.ndarray]:\n",
    "    player_num = state[\"round\"] % len(state[\"players_banks\"])\n",
    "    num_players = len(state['players_banks'])\n",
    "    observations = np.zeros((36, num_players + 4)) # + функция мощности\n",
    "    for card in state['players_banks'][player_num]:\n",
    "        observations[card[0]][0] = 1\n",
    "    for i, bank in enumerate(state['players_info']):\n",
    "        if i != player_num:\n",
    "            if i > player_num:\n",
    "                k = i - player_num\n",
    "            else:\n",
    "                k = num_players + i - player_num\n",
    "            for card in bank:\n",
    "                observations[card[0]][k] = 1\n",
    "\n",
    "    result = np.zeros((num_players + 6, 5, 10))\n",
    "    result[:num_players + 3, 4, 9] = np.ones_like(result[:num_players + 3, 4, 9])\n",
    "    result[num_players + 5, 4, 9] = 1\n",
    "    result[num_players + 4, 4, 9] = 1\n",
    "\n",
    "    for card in state['table']:\n",
    "        observations[card[0]][num_players] = 1\n",
    "        result[num_players + 4, :4, card[2]['power']] = 1\n",
    "    for card in state['bita']:\n",
    "        observations[card[0]][num_players + 1] = 1\n",
    "    for card in state['target']:\n",
    "        observations[card[0]][num_players + 2] = 1\n",
    "        result[num_players + 5, card[2]['type'], card[2]['power']+1:-1] = 1\n",
    "        result[num_players + 4, :4, card[2]['power']] = 1\n",
    "    if len(state['target']) == 0 and len(state['table']) == 0 and state['role'] == 0:\n",
    "        result[num_players + 4, :4, :9] = np.ones_like(result[num_players + 4, :4, :9])\n",
    "        result[num_players + 4, 4, 9] = 0\n",
    "\n",
    "    x_vals = np.array([0.5, 1.5, 2.5, 3.5])\n",
    "    y_vals = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    grid_points = np.array([[x, y] for x in x_vals for y in y_vals])\n",
    "    x_grid = grid_points[:, 0]\n",
    "    y_grid = grid_points[:, 1]\n",
    "    func1 = lambda x, y: -0.5*y+10\n",
    "    func2 = lambda x, y: 0.5*np.cos(x*np.pi + np.pi/2)**2\n",
    "    func3 = lambda x, y: np.where((game.cosir[2]['type'] < x) & (game.cosir[2]['type'] + 1 > x), 10 + (func1(x, -y)) * func2(x, y), 10 - (func1(x, y)) * func2(x, y))\n",
    "    u_vals = func3(x_grid, y_grid)#.reshape(-1, 1)\n",
    "\n",
    "    observations[:, num_players + 3] = u_vals\n",
    "\n",
    "    observations = observations.T\n",
    "\n",
    "    for y_idx in range(4):\n",
    "        for x_idx in range(9):\n",
    "            linear_idx = y_idx * 9 + x_idx\n",
    "            result[:7, y_idx, x_idx] = observations[:, linear_idx]\n",
    "\n",
    "    if state['role'] == 0:\n",
    "        result[0, 4, 9] = 1\n",
    "    else:\n",
    "        result[num_players + 2, 4, 9] = 1\n",
    "\n",
    "    x_vals = np.array([1, 2, 3, 4])\n",
    "    y_vals = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    grid_points = np.array([[x, y] for x in x_vals for y in y_vals] + [[0, 0]])\n",
    "    return result, grid_points\n",
    "print(game.state_history.restore(-1).get_state())\n",
    "obs, grid = create_observations(game.state_history.restore(-1).get_state())\n",
    "print(obs)"
   ],
   "id": "fb8137f68826f593",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'players_banks': [[(26, {'power': 'ace', 'type': 2}, {'power': 8, 'type': 2}, array([1, 0, 1, 0, 0, 1])), (8, {'power': 'ace', 'type': 0}, {'power': 8, 'type': 0}, array([0, 0, 1, 0, 0, 1])), (6, {'power': 'queen', 'type': 0}, {'power': 6, 'type': 0}, array([0, 0, 0, 1, 1, 1])), (4, {'power': '10', 'type': 0}, {'power': 4, 'type': 0}, array([0, 0, 0, 1, 0, 1])), (32, {'power': 'jack', 'type': 3}, {'power': 5, 'type': 3}, array([1, 1, 0, 1, 1, 0])), (16, {'power': 'king', 'type': 1}, {'power': 7, 'type': 1}, array([0, 1, 1, 0, 0, 0]))], [(18, {'power': '6', 'type': 2}, {'power': 0, 'type': 2}, array([1, 0, 0, 0, 0, 1])), (3, {'power': '9', 'type': 0}, {'power': 3, 'type': 0}, array([0, 0, 0, 1, 0, 0])), (23, {'power': 'jack', 'type': 2}, {'power': 5, 'type': 2}, array([1, 0, 0, 1, 1, 0])), (7, {'power': 'king', 'type': 0}, {'power': 7, 'type': 0}, array([0, 0, 1, 0, 0, 0])), (25, {'power': 'king', 'type': 2}, {'power': 7, 'type': 2}, array([1, 0, 1, 0, 0, 0])), (19, {'power': '7', 'type': 2}, {'power': 1, 'type': 2}, array([1, 0, 0, 0, 1, 0]))], [(27, {'power': '6', 'type': 3}, {'power': 0, 'type': 3}, array([1, 1, 0, 0, 0, 1])), (2, {'power': '8', 'type': 0}, {'power': 2, 'type': 0}, array([0, 0, 0, 0, 1, 1])), (33, {'power': 'queen', 'type': 3}, {'power': 6, 'type': 3}, array([1, 1, 0, 1, 1, 1])), (10, {'power': '7', 'type': 1}, {'power': 1, 'type': 1}, array([0, 1, 0, 0, 1, 0])), (0, {'power': '6', 'type': 0}, {'power': 0, 'type': 0}, array([0, 0, 0, 0, 0, 1])), (5, {'power': 'jack', 'type': 0}, {'power': 5, 'type': 0}, array([0, 0, 0, 1, 1, 0]))]], 'players_info': [[], [], []], 'table': [], 'bita': [], 'target': [(24, {'power': 'queen', 'type': 2}, {'power': 6, 'type': 2}, array([1, 0, 0, 1, 1, 1]))], 'finished_players': [], 'busy_cards': [26, 18, 27, 8, 3, 2, 6, 23, 33, 4, 7, 10, 32, 25, 0, 16, 19, 5, 22], 'h': ['attacked'], 'role': 0, 'round': 0, 'cosir': (22, {'power': '10', 'type': 2}, {'power': 4, 'type': 2}, array([1, 0, 0, 1, 0, 1]))}\n",
      "[[[ 0.    0.    0.    0.    1.    0.    1.    0.    1.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    1.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    1.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  ]]\n",
      "\n",
      " [[ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  ]]\n",
      "\n",
      " [[ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  ]]\n",
      "\n",
      " [[ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  ]]\n",
      "\n",
      " [[ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  ]]\n",
      "\n",
      " [[ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  ]]\n",
      "\n",
      " [[ 5.25  5.5   5.75  6.    6.25  6.5   6.75  7.    7.25  0.  ]\n",
      "  [ 5.25  5.5   5.75  6.    6.25  6.5   6.75  7.    7.25  0.  ]\n",
      "  [15.25 15.5  15.75 16.   16.25 16.5  16.75 17.   17.25  0.  ]\n",
      "  [ 5.25  5.5   5.75  6.    6.25  6.5   6.75  7.    7.25  0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]\n",
      "\n",
      " [[ 0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    1.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  ]]\n",
      "\n",
      " [[ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    1.    1.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "  [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    1.  ]]]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T20:59:56.714046Z",
     "start_time": "2025-07-21T20:59:56.712121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#print(obs)\n",
    "#obs = obs.transpose((0, 2, 1))\n",
    "print(obs.shape)\n",
    "print(grid)"
   ],
   "id": "c7f0e036eb35351b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 5, 10)\n",
      "[[1 1]\n",
      " [1 2]\n",
      " [1 3]\n",
      " [1 4]\n",
      " [1 5]\n",
      " [1 6]\n",
      " [1 7]\n",
      " [1 8]\n",
      " [1 9]\n",
      " [2 1]\n",
      " [2 2]\n",
      " [2 3]\n",
      " [2 4]\n",
      " [2 5]\n",
      " [2 6]\n",
      " [2 7]\n",
      " [2 8]\n",
      " [2 9]\n",
      " [3 1]\n",
      " [3 2]\n",
      " [3 3]\n",
      " [3 4]\n",
      " [3 5]\n",
      " [3 6]\n",
      " [3 7]\n",
      " [3 8]\n",
      " [3 9]\n",
      " [4 1]\n",
      " [4 2]\n",
      " [4 3]\n",
      " [4 4]\n",
      " [4 5]\n",
      " [4 6]\n",
      " [4 7]\n",
      " [4 8]\n",
      " [4 9]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T20:59:58.219836Z",
     "start_time": "2025-07-21T20:59:56.723227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MIONet2d(nn.Module):\n",
    "    def __init__(self, nonlinear_dim, linear_dim, trunk_input_dim=2, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Общая Branch сеть (для точек x, y ∈ координатной сетке)\n",
    "        self.branch_general = nn.Sequential(\n",
    "            nn.Conv2d(nonlinear_dim, 32, kernel_size=3, padding=1), nn.SELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32, latent_dim)\n",
    "        )\n",
    "\n",
    "        # Специальная линейная сеть для channel=0 и координаты (-1, -1)\n",
    "        self.branch_lin = nn.Sequential(\n",
    "            nn.Conv2d(linear_dim, 16, kernel_size=1, padding=0), #nn.SELU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16, latent_dim)  # Только channel 0\n",
    "        )\n",
    "\n",
    "        # Trunk сеть\n",
    "        self.trunk_net = nn.Sequential(\n",
    "            nn.Linear(trunk_input_dim, 32), nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim)\n",
    "        )\n",
    "\n",
    "    def target_positions(self, lin_input):\n",
    "        dots = []\n",
    "        pos = torch.prod(lin_input, dim=1) # (B, H, W)\n",
    "        for i in range(pos.shape[1] - 1):\n",
    "            for j in range(pos.shape[2] - 1):\n",
    "                dots.append(pos[:, i, j])\n",
    "        dots.append(pos[:, -1, -1])\n",
    "        return torch.stack(dots, dim=1)\n",
    "\n",
    "    def forward(self, nonlinear_func, linear_func, coords):\n",
    "        \"\"\"\n",
    "        nonlinear_func: (B, C1, H, W)\n",
    "        linear_func: (B, C2, H, W)\n",
    "        coords: (B, N, 2) — (x, y) координаты\n",
    "        Returns:\n",
    "            Q-values: (B, N)\n",
    "        \"\"\"\n",
    "        B, N, _ = coords.shape\n",
    "\n",
    "        # --- Nonlinear branch (f1,...,fn) ---\n",
    "        nonlinear_out = self.branch_general(nonlinear_func)  # (B, latent_dim)\n",
    "        nonlinear_out = nonlinear_out.unsqueeze(1).expand(-1, N - 1, -1)  # (B, N, latent_dim)\n",
    "\n",
    "        # --- Linear branch (h1,...,hn)\n",
    "        linear_out = self.branch_lin(linear_func)  # (B, latent_dim)\n",
    "        linear_out = linear_out.unsqueeze(1).expand(-1, 1, -1)  # (B, 1, latent_dim)\n",
    "\n",
    "        gen_branch = torch.cat([nonlinear_out, linear_out], dim=1)\n",
    "        # --- Trunk сеть ---\n",
    "        coords_flat = coords.view(B * N, -1)  # (B * N, 2)\n",
    "        trunk_out = self.trunk_net(coords_flat).view(B, N, -1)  # (B, N, latent_dim)\n",
    "\n",
    "        # --- Masking ---\n",
    "        target_positions = self.target_positions(linear_func)\n",
    "\n",
    "        # --- Point-wise product + Sum ---\n",
    "        q_vals = target_positions * torch.sum(gen_branch * trunk_out, dim=-1)  # (B, N)\n",
    "\n",
    "        return q_vals"
   ],
   "id": "56dae0bd2a8217a5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T20:59:58.232055Z",
     "start_time": "2025-07-21T20:59:58.225836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_lin_tensor(obs, role):\n",
    "    if role == 0:\n",
    "        return torch.tensor(np.concatenate([obs[0:1, :, :], obs[7:8, :, :]], axis=0), dtype=torch.float32)\n",
    "    else:\n",
    "        return torch.tensor(np.concatenate([obs[0:1, :, :], obs[8:9, :, :]], axis=0), dtype=torch.float32)\n",
    "\n",
    "def create_nonlin_tensor(obs, role):\n",
    "    if role == 0:\n",
    "        return torch.tensor(np.concatenate([obs[1:7, :, :], obs[8:9, :, :]], axis=0), dtype=torch.float32)\n",
    "    else:\n",
    "        return torch.tensor(obs[1:8, :, :], dtype=torch.float32)\n",
    "\n",
    "def target_positions(lin_input):\n",
    "    dots = []\n",
    "    pos = torch.prod(lin_input, dim=1) # (B, H, W)\n",
    "    for i in range(pos.shape[1] - 1):\n",
    "        for j in range(pos.shape[2] - 1):\n",
    "            dots.append(pos[:, i, j])\n",
    "    dots.append(pos[:, -1, -1])\n",
    "    return torch.stack(dots, dim=1)\n",
    "\n",
    "nonlinear_input = create_nonlin_tensor(obs, 0).unsqueeze(0)\n",
    "linear_input = create_lin_tensor(obs, 0).unsqueeze(0)\n",
    "coords_input = torch.tensor(grid, dtype=torch.float32).unsqueeze(0)\n",
    "print(nonlinear_input.size())\n",
    "print(linear_input)\n",
    "print(coords_input.size())\n",
    "print(target_positions(linear_input))"
   ],
   "id": "ce1afff33d85b261",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 5, 10])\n",
      "tensor([[[[0., 0., 0., 0., 1., 0., 1., 0., 1., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]]])\n",
      "torch.Size([1, 37, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1.]])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T20:59:58.250266Z",
     "start_time": "2025-07-21T20:59:58.246056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_q_approx(game: FoolGame, player_num, pred_modelA: torch.nn.Module, pred_modelD: torch.nn.Module) -> tuple[float, bool]:\n",
    "    while game.round % game.num_players != player_num:\n",
    "        state = game.state_history.restore(-1).get_state()\n",
    "        obs, grid = create_observations(state)\n",
    "        nonlinear_input = create_nonlin_tensor(obs, state['role']).unsqueeze(0).to(torch.device('cuda:0'))\n",
    "        linear_input = create_lin_tensor(obs, state['role']).unsqueeze(0).to(torch.device('cuda:0'))\n",
    "        coords_input = torch.tensor(grid, dtype=torch.float32).unsqueeze(0).to(torch.device('cuda:0'))\n",
    "\n",
    "        if game.role == 0:\n",
    "            Q_values = pred_modelA(nonlinear_input, linear_input, coords_input)\n",
    "        else:\n",
    "            Q_values = pred_modelD(nonlinear_input, linear_input, coords_input)\n",
    "        _, not_terminal, _ = game.step(torch.argmax(Q_values).item())\n",
    "        if not not_terminal:\n",
    "            return 0, False\n",
    "\n",
    "    state = game.state_history.restore(-1).get_state()\n",
    "    obs, grid = create_observations(state)\n",
    "    nonlinear_input = create_nonlin_tensor(obs, state['role']).unsqueeze(0).to(torch.device('cuda:0'))\n",
    "    linear_input = create_lin_tensor(obs, state['role']).unsqueeze(0).to(torch.device('cuda:0'))\n",
    "    coords_input = torch.tensor(grid, dtype=torch.float32).unsqueeze(0).to(torch.device('cuda:0'))\n",
    "    if game.role == 0:\n",
    "        Q_values = pred_modelA(nonlinear_input, linear_input, coords_input)\n",
    "    else:\n",
    "        Q_values = pred_modelD(nonlinear_input, linear_input, coords_input)\n",
    "    return torch.max(Q_values).item(), True\n"
   ],
   "id": "93b66ca8aac91fa0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T21:02:03.928225Z",
     "start_time": "2025-07-21T20:59:58.252265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "B, N = 512, 37\n",
    "modelA = MIONet2d(7, 2).to(torch.device('cuda:0'))\n",
    "weights = modelA.state_dict()\n",
    "modelA_eval = MIONet2d(7, 2).to(torch.device('cuda:0'))\n",
    "modelA_eval.load_state_dict(weights)\n",
    "modelD = MIONet2d(7, 2).to(torch.device('cuda:0'))\n",
    "weights = modelD.state_dict()\n",
    "modelD_eval = MIONet2d(7, 2).to(torch.device('cuda:0'))\n",
    "modelD_eval.load_state_dict(weights)\n",
    "\n",
    "optimizerA = optim.Adam(modelA.parameters(), lr=0.0001)\n",
    "optimizerD = optim.Adam(modelD.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "epochs = 10\n",
    "discounting = 0.99\n",
    "lossesA = []\n",
    "lossesD = []\n",
    "games = [FoolGame(36, 4, 6, 3, names=names) for i in range(B)]\n",
    "[game.redo() for game in games]\n",
    "\n",
    "modelA.train()\n",
    "modelD.train()\n",
    "modelA_eval.eval()\n",
    "modelD_eval.eval()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    infoLogger.info(f\"epoch={epoch}\")\n",
    "    # Updating evaluation model weights\n",
    "    if (epoch % 5 == 0 and epoch != 0) or epoch == 1:\n",
    "        weights = modelA.state_dict()\n",
    "        modelA_eval.load_state_dict(weights)\n",
    "        weights = modelD.state_dict()\n",
    "        modelD_eval.load_state_dict(weights)\n",
    "        infoLogger.info(f\"updating eval model weights\")\n",
    "\n",
    "    state_nonlinearA = []\n",
    "    state_linearA = []\n",
    "\n",
    "    state_nonlinearD = []\n",
    "    state_linearD = []\n",
    "\n",
    "    coords_input = None\n",
    "\n",
    "    D_idxs = []\n",
    "    A_idxs = []\n",
    "\n",
    "    # Capturing observables from games\n",
    "    infoLogger.info(f\"capturing observables\")\n",
    "    for i, game in enumerate(games):\n",
    "        state = game.state_history.restore(-1).get_state()\n",
    "        obs, grid = create_observations(state)\n",
    "\n",
    "        nonlinear_input = create_nonlin_tensor(obs, state['role']).unsqueeze(0)\n",
    "        linear_input = create_lin_tensor(obs, state['role']).unsqueeze(0)\n",
    "        if coords_input is None:\n",
    "            coords_input = torch.tensor(grid, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        if state['role'] == 0:\n",
    "            state_nonlinearA.append(nonlinear_input)\n",
    "            state_linearA.append(linear_input)\n",
    "            A_idxs.append(i)\n",
    "        else:\n",
    "            state_nonlinearD.append(nonlinear_input)\n",
    "            state_linearD.append(linear_input)\n",
    "            D_idxs.append(i)\n",
    "        if i % 50 == 0:\n",
    "            infoLogger.info(f\"game={i}\")\n",
    "\n",
    "    # Approximating Q-values\n",
    "    if len(state_nonlinearA) > 0:\n",
    "        t_state_nonlinearA = torch.cat(state_nonlinearA).to(torch.device('cuda:0'))#.detach()\n",
    "        t_state_linearA = torch.cat(state_linearA).to(torch.device('cuda:0'))\n",
    "        t_coords_inputA = coords_input.repeat(t_state_linearA.shape[0], 1, 1).to(torch.device('cuda:0'))#.detach()\n",
    "\n",
    "        Q_valuesA = modelA(t_state_nonlinearA, t_state_linearA, t_coords_inputA)\n",
    "        infoLogger.info(f\"Approximating attacker Q values\")\n",
    "\n",
    "    if len(state_linearD) > 0:\n",
    "        t_state_nonlinearD = torch.cat(state_nonlinearD).to(torch.device('cuda:0'))#.detach()\n",
    "        t_state_linearD = torch.cat(state_linearD).to(torch.device('cuda:0'))\n",
    "        t_coords_inputD = coords_input.repeat(t_state_linearD.shape[0], 1, 1).to(torch.device('cuda:0'))#.detach()\n",
    "\n",
    "        Q_valuesD = modelD(t_state_nonlinearD, t_state_linearD, t_coords_inputD)\n",
    "        infoLogger.info(f\"Approximating defender Q values\")\n",
    "\n",
    "    # Applying Bellman formula\n",
    "    h, m = 0, 0\n",
    "    ngA = []\n",
    "    ngD = []\n",
    "    rewD = torch.zeros(len(state_linearD), 37).to(torch.device('cuda:0'))\n",
    "    rewA = torch.zeros(len(state_linearA), 37).to(torch.device('cuda:0'))\n",
    "    contA = []\n",
    "    contD = []\n",
    "    infoLogger.info(f\"Applying Bellman formula\")\n",
    "    for i, game in enumerate(games):\n",
    "        infoLogger.info(f\"game={i}\")\n",
    "        if i in D_idxs:\n",
    "            Q_v = Q_valuesD[h, :] # [37]\n",
    "            for j, q_val in enumerate(Q_v):\n",
    "                if q_val > 1e-7 or q_val < 1e-7:\n",
    "                    new_game: FoolGame = game.copy()\n",
    "                    rew, cont, player_not_ended = new_game.step(j)\n",
    "                    if player_not_ended and cont:\n",
    "                        Q_next, cont = find_q_approx(new_game, game.round % game.num_players, modelA_eval, modelD_eval)\n",
    "                        if cont:\n",
    "                            rew += Q_next * discounting\n",
    "                    rewD[h, j] = rew\n",
    "                else:\n",
    "                    rewD[h, j] = 0\n",
    "            h += 1\n",
    "        if i in A_idxs:\n",
    "            Q_v = Q_valuesA[m, :] # [37]\n",
    "            for j, q_val in enumerate(Q_v):\n",
    "                if q_val > 1e-7 or q_val < 1e-7:\n",
    "                    new_game: FoolGame = game.copy()\n",
    "                    rew, cont, player_not_ended = new_game.step(j)\n",
    "                    if player_not_ended and cont:\n",
    "                        Q_next, cont = find_q_approx(new_game, game.round % game.num_players, modelA_eval, modelD_eval)\n",
    "                        if cont:\n",
    "                            rew += Q_next * discounting\n",
    "                    rewA[m, j] = rew\n",
    "                else:\n",
    "                    rewA[m, j] = 0\n",
    "            m += 1\n",
    "\n",
    "    # Optimizing process\n",
    "    infoLogger.info(f\"Optimizing Q functions\")\n",
    "    if len(state_linearA) > 0:\n",
    "        optimizerA.zero_grad()\n",
    "        loss = criterion(Q_valuesA, rewA)\n",
    "        loss.backward()\n",
    "        optimizerA.step()\n",
    "        lossesA.append(loss.item())\n",
    "\n",
    "    if len(state_linearD) > 0:\n",
    "        optimizerD.zero_grad()\n",
    "        loss = criterion(Q_valuesD, rewD)\n",
    "        loss.backward()\n",
    "        optimizerD.step()\n",
    "        lossesD.append(loss.item())\n",
    "\n",
    "    # Making \\eps -greedy moves\n",
    "    infoLogger.info(f\"Making \\eps -greedy moves\")\n",
    "    h, m = 0, 0\n",
    "    epsilon = 0.15\n",
    "    new_games = []\n",
    "    for i, game in enumerate(games):\n",
    "        infoLogger.info(f\"game={i}\")\n",
    "        if i in D_idxs:\n",
    "            possible_actions = torch.nonzero(Q_valuesD[m, :]).tolist()\n",
    "            print(\"D:\", torch.argmax(Q_valuesD[m, :], dim=0).item())\n",
    "            if random.random() < epsilon:\n",
    "                action = random.choice(possible_actions)[0]\n",
    "            else:\n",
    "                action = torch.argmax(Q_valuesD[m, :]).item()\n",
    "            _, cont, _ = game.step(action)\n",
    "            if cont:\n",
    "                new_games.append(game)\n",
    "            m += 1\n",
    "        else:\n",
    "            possible_actions = torch.nonzero(Q_valuesA[h, :]).tolist()\n",
    "            print(\"A:\", torch.argmax(Q_valuesA[h, :], dim=0).item())\n",
    "            if random.random() < epsilon:\n",
    "                action = random.choice(possible_actions)[0]\n",
    "            else:\n",
    "                action = torch.argmax(Q_valuesA[h, :]).item()\n",
    "            print(action)\n",
    "            _, cont, _ = game.step(action)\n",
    "            if cont:\n",
    "                new_games.append(game)\n",
    "            h += 1\n",
    "    games = new_games\n",
    "    added_games = [FoolGame(36, 4, 6, 3, names=names) for i in range(B - len(games))]\n",
    "    [game.redo() for game in added_games]\n",
    "    games += added_games\n",
    "\n",
    "    print(\"epoch:\", epoch)\n",
    "    print(\"lossA:\", lossesA[-1])\n",
    "    print(\"lossD:\", lossesD[-1])\n",
    "\n",
    "plt.plot(np.arange(1, len(lossesA) + 1), lossesA)\n",
    "plt.show()\n",
    "plt.plot(np.arange(1, len(lossesD) + 1), lossesD)\n",
    "plt.show()\n"
   ],
   "id": "5001025c146e1fb6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:141: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:141: SyntaxWarning: invalid escape sequence '\\e'\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_37364\\2723173326.py:141: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  infoLogger.info(f\"Making \\eps -greedy moves\")\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_37364\\2723173326.py:141: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  infoLogger.info(f\"Making \\eps -greedy moves\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 116\u001B[0m\n\u001B[0;32m    114\u001B[0m rew, cont, player_not_ended \u001B[38;5;241m=\u001B[39m new_game\u001B[38;5;241m.\u001B[39mstep(j)\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m player_not_ended \u001B[38;5;129;01mand\u001B[39;00m cont:\n\u001B[1;32m--> 116\u001B[0m     Q_next, cont \u001B[38;5;241m=\u001B[39m \u001B[43mfind_q_approx\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_game\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mround\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mgame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_players\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodelA_eval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodelD_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    117\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m cont:\n\u001B[0;32m    118\u001B[0m         rew \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m Q_next \u001B[38;5;241m*\u001B[39m discounting\n",
      "Cell \u001B[1;32mIn[9], line 13\u001B[0m, in \u001B[0;36mfind_q_approx\u001B[1;34m(game, player_num, pred_modelA, pred_modelD)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     12\u001B[0m     Q_values \u001B[38;5;241m=\u001B[39m pred_modelD(nonlinear_input, linear_input, coords_input)\n\u001B[1;32m---> 13\u001B[0m _, not_terminal, _ \u001B[38;5;241m=\u001B[39m \u001B[43mgame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mQ_values\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m not_terminal:\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\PEINO\\models\\PockerRL\\Environment.py:903\u001B[0m, in \u001B[0;36mFoolGame.step\u001B[1;34m(self, action, save)\u001B[0m\n\u001B[0;32m    901\u001B[0m \u001B[38;5;66;03m#print(\"round after:\", self.round)\u001B[39;00m\n\u001B[0;32m    902\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m save:\n\u001B[1;32m--> 903\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_game\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    904\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m player \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinished_players:\n\u001B[0;32m    905\u001B[0m     terminal \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\PEINO\\models\\PockerRL\\Environment.py:466\u001B[0m, in \u001B[0;36mFoolGame.save_game\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    454\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21msave_game\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    455\u001B[0m     state_dict \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplayers_banks\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mplayers_banks,\n\u001B[0;32m    456\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplayers_info\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mplayers_info,\n\u001B[0;32m    457\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtable\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtable,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    464\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mround\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mround,\n\u001B[0;32m    465\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcosir\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcosir}\n\u001B[1;32m--> 466\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_history\u001B[38;5;241m.\u001B[39msave(\u001B[43mGameActionMomento\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\PEINO\\models\\PockerRL\\Environment.py:62\u001B[0m, in \u001B[0;36mGameActionMomento.__init__\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, action: \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 62\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m=\u001B[39m \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:136\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    134\u001B[0m copier \u001B[38;5;241m=\u001B[39m _deepcopy_dispatch\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 136\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:221\u001B[0m, in \u001B[0;36m_deepcopy_dict\u001B[1;34m(x, memo, deepcopy)\u001B[0m\n\u001B[0;32m    219\u001B[0m memo[\u001B[38;5;28mid\u001B[39m(x)] \u001B[38;5;241m=\u001B[39m y\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m--> 221\u001B[0m     y[deepcopy(key, memo)] \u001B[38;5;241m=\u001B[39m \u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:136\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    134\u001B[0m copier \u001B[38;5;241m=\u001B[39m _deepcopy_dispatch\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 136\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:196\u001B[0m, in \u001B[0;36m_deepcopy_list\u001B[1;34m(x, memo, deepcopy)\u001B[0m\n\u001B[0;32m    194\u001B[0m append \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mappend\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m x:\n\u001B[1;32m--> 196\u001B[0m     append(\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:136\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    134\u001B[0m copier \u001B[38;5;241m=\u001B[39m _deepcopy_dispatch\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 136\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:201\u001B[0m, in \u001B[0;36m_deepcopy_tuple\u001B[1;34m(x, memo, deepcopy)\u001B[0m\n\u001B[0;32m    200\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_deepcopy_tuple\u001B[39m(x, memo, deepcopy\u001B[38;5;241m=\u001B[39mdeepcopy):\n\u001B[1;32m--> 201\u001B[0m     y \u001B[38;5;241m=\u001B[39m [\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m x]\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001B[39;00m\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001B[39;00m\n\u001B[0;32m    204\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\copy.py:143\u001B[0m, in \u001B[0;36mdeepcopy\u001B[1;34m(x, memo, _nil)\u001B[0m\n\u001B[0;32m    141\u001B[0m copier \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__deepcopy__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 143\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    145\u001B[0m     reductor \u001B[38;5;241m=\u001B[39m dispatch_table\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T20:51:50.936481100Z",
     "start_time": "2025-07-20T20:36:06.694407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "modelA.eval()\n",
    "\n",
    "nonlinear_input = create_nonlin_tensor(obs, 0).unsqueeze(0).to(torch.device('cuda:0'))\n",
    "linear_input = create_lin_tensor(obs, 0).unsqueeze(0).to(torch.device('cuda:0'))\n",
    "coords_input = torch.tensor(grid, dtype=torch.float32).unsqueeze(0).to(torch.device('cuda:0'))\n",
    "print(nonlinear_input.size())\n",
    "print(linear_input)\n",
    "print(coords_input.size())\n",
    "print(target_positions(linear_input))\n",
    "\n",
    "print(modelA(nonlinear_input, linear_input, coords_input).size())\n",
    "print(modelA(nonlinear_input, linear_input, coords_input))"
   ],
   "id": "f3af461ab6defee0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 5, 10])\n",
      "tensor([[[[0., 1., 1., 0., 1., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "         [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]]], device='cuda:0')\n",
      "torch.Size([1, 37, 2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1.]], device='cuda:0')\n",
      "torch.Size([1, 37])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0469]], device='cuda:0', grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
